# Nothing5 파일 분류기 프로젝트 구조 분석 및 개선점 제안 보고서

**작성자:** Manus AI Agent
**작성일:** 2026년 1월 5일
**대상 프로젝트:** Chiriri722/Nothing5 (LLM 기반 파일 자동 분류 시스템)

## 1. 프로젝트 현황 및 구조 진단

`Nothing5` 프로젝트는 LLM(대규모 언어 모델)을 활용하여 파일 내용을 분석하고 자동으로 분류/이동하는 시스템으로, **모듈화 및 비용 최적화**에 중점을 두고 개발되고 있습니다. 특히, 이전 AI 에이전트가 제안한 **프로젝트 검토 및 최적화 제안서 (V.0.1)**의 내용이 상당 부분 반영되어 안정적인 구조를 갖추고 있습니다.

### 1.1. 핵심 구조 분석

| 모듈 | 역할 | 주요 기능 및 특징 | 평가 |
| :--- | :--- | :--- | :--- |
| `main.py` | 진입점 | CLI/GUI 모드 선택 및 인자 처리. | **양호** - 깔끔한 진입점 역할 수행. |
| `modules/app.py` | 애플리케이션 코어 | 모든 모듈 통합 및 관리. `asyncio` 기반의 비동기 처리 및 `Semaphore`를 통한 동시성 제어(최대 20개) 구현. | **우수** - 확장성 및 성능을 고려한 비동기 구조. |
| `config/config.py` | 전역 설정 | 환경 변수, 사용자 설정 파일(`user_settings.json`) 로드. LLM 모델, API 키, 로깅 레벨 등 중앙 관리. | **우수** - 유연한 LLM 백엔드 전환 구조(OpenAI, Gemini, Claude)를 갖춤. |
| `modules/extractor.py` | 파일 내용 추출 | PDF, DOCX, TXT, 코드, 이미지 등 다양한 파일 형식 지원. | **양호** - `asyncio.to_thread`를 사용한 비동기 추출 지원. |
| `modules/classifier.py` | 파일 분류 로직 | **계층적 필터링** 및 **LLM 분류** 구현. | **우수** - 비용 최적화 전략(계층적 필터링)이 핵심 로직에 반영됨. |

### 1.2. 비용 최적화 전략 반영 현황

이전 제안서에서 강조된 **LLM API 비용 절감** 전략의 반영 현황은 다음과 같습니다.

| 전략 | `Nothing5` 반영 현황 | 상세 분석 |
| :--- | :--- | :--- |
| **계층적 필터링** | **반영 완료** (`classifier.py`) | 파일명 키워드 및 확장자 규칙을 먼저 적용하여 LLM 호출을 최소화하는 로직이 구현됨. |
| **스마트 요약 추출** | **부분 반영** (`extractor.py`) | 대용량 `.txt` 파일에 대해 **앞 1000자 + 뒤 1000자**만 추출하는 로직이 구현됨. |
| **로컬 캐싱 및 규칙 학습** | **미반영** (향후 로드맵) | 분류 결과를 로컬 DB에 저장하여 재활용하는 로직은 아직 구현되지 않았습니다. |

## 2. 개선점 및 향후 개발 제안

현재 프로젝트는 안정적인 구조와 비용 최적화의 기반을 잘 다져놓았으나, 성능, 안정성, 그리고 사용자 경험 측면에서 다음과 같은 개선을 제안합니다.

### 2.1. 비용 최적화 및 성능 개선 (가장 시급)

| 개선 항목 | 상세 제안 | 기대 효과 |
| :--- | :--- | :--- |
| **스마트 요약 추출 확장** | `extractor.py`의 **PDF 및 DOCX** 추출 로직에도 `.txt` 파일과 동일하게 **앞 1000자 + 뒤 1000자** 요약 로직을 적용해야 합니다. 현재는 대용량 PDF/DOCX 파일이 LLM에 전송될 경우 비용 폭탄의 위험이 있습니다. | 모든 대용량 문서에 대한 LLM 컨텍스트 크기 및 API 비용 절감. |
| **로컬 캐싱 시스템 구현** | `modules/classifier.py`에 `modules/history_db.py`를 활용하여 **분류 결과를 캐싱**하는 로직을 추가해야 합니다. (제안서의 3단계) | 동일 파일 또는 유사 파일 재분류 시 LLM 호출을 생략하여 **비용을 획기적으로 절감**하고 응답 속도를 개선. |
| **이미지 OCR/Vision API 연동** | 현재 이미지 파일은 메타데이터만 추출하고 있습니다. **Vision API** (예: `gpt-4o-mini` 또는 로컬 OCR 라이브러리)를 연동하여 이미지 내 텍스트를 추출하고 분류에 활용해야 합니다. | 이미지 파일 분류의 정확도 향상 및 활용 범위 확대. |

### 2.2. 안정성 및 사용자 경험 개선

| 개선 항목 | 상세 제안 | 기대 효과 |
| :--- | :--- | :--- |
| **설정 파일 누락 오류 방지** | `config/config.py`에서 `USER_SETTINGS_FILE`이 없을 경우 기본값을 사용하고 있지만, `OPENAI_API_KEY`가 비어있을 경우 `FileClassifierApp` 초기화 시 **명시적인 오류 메시지**를 출력하도록 `validate_config()` 함수를 강화해야 합니다. | 사용자에게 API 키 설정의 필요성을 명확히 안내하여 초기 실행 오류를 줄임. |
| **LLM 폴백 로직 강화** | `classifier.py`의 `_call_llm_api` 호출 실패 시, 현재는 `_create_fallback_result`를 통해 파일명 기반으로 분류하고 있습니다. 여기에 **파일 크기, 생성일 등 메타데이터**를 활용한 추가적인 폴백 규칙을 도입하여 분류의 정확도를 높여야 합니다. | LLM API 장애 시에도 분류 품질을 일정 수준 유지. |
| **GUI/CLI 상태 동기화** | `modules/app.py`에서 `run_gui()`와 `run_cli()`가 각각 다른 방식으로 애플리케이션을 실행합니다. `CLIHandler`가 `FileClassifierApp`의 상태(예: `is_paused`, `stats`)를 GUI와 동일하게 접근하고 업데이트할 수 있도록 **상태 관리 인터페이스**를 명확히 정의해야 합니다. | GUI와 CLI 간의 기능 일관성 및 상태 관리 용이성 확보. |

## 3. 결론 및 다음 단계 제안

`Nothing5` 프로젝트는 **LLM 기반 파일 분류기의 핵심 기능과 비용 최적화 전략의 기반**을 성공적으로 구축했습니다.

**가장 시급한 다음 단계**는 다음과 같습니다.

1.  **Extractor 모듈 개선**: PDF/DOCX 파일에 대한 스마트 요약 추출 로직을 구현하여 LLM API 비용 폭탄의 위험을 제거합니다.
2.  **Classifier 모듈 개선**: 분류 결과를 로컬 DB에 캐싱하는 로직을 구현하여 LLM 호출 횟수를 최소화합니다.

이 두 가지 개선을 통해 프로젝트의 **실질적인 비용 효율성**을 확보할 수 있습니다. 다음 단계로 진행할 개선 항목을 선택해 주시면, 해당 모듈의 코드 구현을 진행하겠습니다.

---
### 참고 문헌

[1] Chiriri722/Nothing5 GitHub Repository. (2026). [https://github.com/Chiriri722/Nothing5/](https://github.com/Chiriri722/Nothing5/)
[2] Chiriri722. (2025). Project Review & Optimization Proposal (V.0.1) .md. *Chiriri722/Nothing5*. [https://github.com/Chiriri722/Nothing5/blob/main/Project%20Review%20&%20Optimization%20Proposal%20(V.0.1)%20.md](https://github.com/Chiriri722/Nothing5/blob/main/Project%20Review%20&%20Optimization%20Proposal%20(V.0.1)%20.md)
